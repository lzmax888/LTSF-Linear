Args in experiment:
Namespace(activation='gelu', batch_size=64, c_out=7, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='exchange_rate.csv', dec_in=7, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=1, factor=1, features='S', freq='h', gpu=0, individual=False, is_training=1, itr=1, label_len=48, learning_rate=0.001, loss='mse', lradj='type1', model='Mega_Linear', model_id='Exchange_336_192', moving_avg=25, n_heads=8, num_workers=35, output_attention=False, patience=3, pred_len=192, root_path='./dataset/', seq_len=336, target='OT', test_flop=False, train_epochs=1, use_amp=False, use_gpu=False, use_multi_gpu=False)
Use CPU
>>>>>>>start training : Exchange_336_192_Mega_Linear_custom_ftS_sl336_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4784
val 569
test 1326
Epoch: 1 cost time: 7.604626655578613
Epoch: 1, Steps: 74 | Train Loss: 0.4183553 Vali Loss: 0.3037388 Test Loss: 0.1987613
Validation loss decreased (inf --> 0.303739).  Saving model ...
Updating learning rate to 0.001
>>>>>>>testing : Exchange_336_192_Mega_Linear_custom_ftS_sl336_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1326
mse:0.19876132905483246, mae:0.3691984713077545
